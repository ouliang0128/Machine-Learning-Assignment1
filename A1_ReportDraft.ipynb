{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.4"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "A1_ReportDraft.ipynb",
      "version": "0.3.2",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HD65WPLREIg",
        "colab_type": "text"
      },
      "source": [
        "# Review Report on \"LEARNING INTERNAL REPRESENTATIONS BY ERROR PROPAGATION\"\n",
        "\n",
        "Name: Liang Ou\n",
        "\n",
        "Student ID: 13060835\n",
        "\n",
        "[Link to notbook version of this report](https://github.com/ouliang0128/Machine-Learning-Assignment1/blob/master/A1_ReportDraft.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSZebyoNREIh",
        "colab_type": "text"
      },
      "source": [
        "## Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTIee1M5XzSd",
        "colab_type": "text"
      },
      "source": [
        "Minsky and Papert (1969) proposed the problem of the many-layered version neural network lacks powerful convergence theorem. To solve this problem, the authors of this book have found a learning result sufficiently powerful to demonstrate that their pessimism about learning in multi-layer machines was misplaced.\n",
        "The authors point out that without hidden layers in a neural network, it is unable to learn certain mappings between similar inputs and different outputs using the similarity of patterns. However, by adding internal representation units to augment the original input pattern, the network can perform any mapping from input to output. However, optimizing weights between units of such network is a complicated job. This book proposes a so called “backpropagation” method to address this optimization problem.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SU2-vmSoREIi",
        "colab_type": "text"
      },
      "source": [
        "## Content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZ9BqhUZREIj",
        "colab_type": "text"
      },
      "source": [
        "The main challenge of the book is defining a generalized learning procedure for multi-layer perceptron network. This is because multi-layer neural networks have hidden units between input layer and output layer, thus change of weights between layers influence the inputs of the units in higher layers, which bring a difficulty to optimize these weights. Although there are several methods for updating weights, they all have limitations. Therefore, network with hidden layers units cannot use a simple rule, such as \"delta rule”, for all problem, 3 response is proposed:\n",
        "1.\tCompetitive Learning: hidden units develop by simple unsupervised learning rules.\n",
        ">-\tThe disadvantage of the response is that there is no guarantee that hidden units appropriate for the required mapping are developed.\n",
        "2.\tassume an internal representation: \n",
        ">-\tappropriate for verb learning and word perception\n",
        "3.\tdevelop a learning procedure which is adjustable for task variations. \n",
        ">a)\tBoltzmann machines:\n",
        ">- i.\tUses stochastic units\n",
        ">- ii.\tReach equilibrium in two different phases\n",
        ">- iii.\tlimited to symmetric networks\n",
        "\n",
        "    >   b)\tstochastic units by Barto (1985)\n",
        " \n",
        "    >   c)\tgeneralized delta rule.\n",
        ">- i.\tdeterministic units\n",
        ">- ii.\tinvolves only local computations\n",
        ">- iii.\ta clear generalization of the delta rule\n",
        "\n",
        "    >   d)\tlearning-logic (Parker (1985))\n",
        ">-\ta similar generalization with “generalized delta rule”\n",
        "    >   e)\tLe Cun (1985) has also studied a roughly similar learning scheme.\n",
        "\n",
        "This book proposed a generalized delta rule by backpropagation of the error signal. This approach is tested in several kind of problems and yields significant success. The detail of this approach and its results are discussed in the following section.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-x1PkGXREIj",
        "colab_type": "text"
      },
      "source": [
        "## Innovation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBgdNafMREIk",
        "colab_type": "text"
      },
      "source": [
        "The learning procedure this book proposed is called “The Generalized Delta Rule”.\n",
        "The three steps of delta rule are: \n",
        "1.\tuses the input vector to produce its output vector\n",
        "2.\tcompares this with the desired output or target vector.\n",
        "3.\tthe difference is reduced by change weights\n",
        "**The standard delta rule is given by the following formula:**\n",
        "$$\n",
        "∆_p w_{ji}= \\eta(t_{pj}-o_{pj})i_{pi}=\\eta\\delta_{pj}i_{pi}\n",
        "$$\n",
        "\n",
        ">For $w_{ji}$, j refers to the jth perceptron in the output layer, i refers to the ith perceptron in the input layer. This formula explains weights will change by measuring the difference between target output and actual output. $\\eta$ is the learning rate. This can be derived by taking the partial derivative of Error (defined by $E_p= \\frac{1}{2}\\sum_j(t_{pj}-o_{pj})^2$) with respect to $w_{ji}$. It is given by:($-\\frac{∂E_p}{∂w_{ji}}=δ_{pj} i_{pi}$).\n",
        "\n",
        "**Error signal:**\n",
        "$$\n",
        "δ_{pj}= f'_j (net_pj)∑_kδ_{pk} w_{kj} \n",
        "$$\n",
        "This function means the “error signal” of a perceptron is calculated by its firing strength’s derivative multiplies the sum weighted “error signal” of its connected upper perceptron. If the perceptron is output perceptron, the last term is $(t_{pj}-o_{pj} )$. Error signal means the derivative of the error with respect to net input, defined by the formula $δ_{pj}=-\\frac{∂E_p}{∂net_{pj}}$\n",
        "\n",
        "**The delta rule for semilinear activation functions in feedforward networks:**\n",
        "\n",
        "By adding hidden units w may converge at local minima.\n",
        "\n",
        "The activation function is defined as $o_{pj}=\\frac{1}{1+e^{∑_iw_{ji}o_{pi}\\theta_j}}$, its derivative is calculated through $\\frac{∂o_{pj}}{∂net_{pj}}=o_{pj}(1-o_{pj})$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qa9-LfljLP0",
        "colab_type": "text"
      },
      "source": [
        "**SIMULATION RESULTS**\n",
        "\n",
        "After several simulations, the authors found there are two major local minima issues involved in their optimization procedure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xA5eylzjVY9",
        "colab_type": "text"
      },
      "source": [
        "**Problem 1: XOR problem**\n",
        "\n",
        "An experiment of XOR problem with only one hidden layer shown that $P=280-33 log_2⁡H$, in which P is the average number of presentations to solve the problem, H is the number of hidden units employed. The formula implies that as the number of hidden units increases, the solving time reduces. Another finding it the within the range from 0.1 to 0.75, the larger the learning rate, the faster the converging speed. For the learning rate, beyond 0.75, the predictor will be unstable.\n",
        "As it is shown in **Figure 1**, biases of all nodes are written inside the circles and weights are presented beside connection lines. For example, the left hidden unit will be activated if the left input is off or the right input is on.\n",
        "\n",
        "\n",
        "![Figure 1. Network structure for solving XOR problem. \n",
        "](https://github.com/ouliang0128/Machine-Learning-Assignment1/blob/master/figure_1.png?raw=true)\n",
        "\n",
        "**Figure 1.** Network structure for solving XOR problem\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESY7PEDKjm1H",
        "colab_type": "text"
      },
      "source": [
        "**Problem 2:** \n",
        "\n",
        "If the answer is different for similar input patterns, the hidden layer is needed to interpret the problem.\n",
        "\n",
        "As **Figure 2** shows an converged network structure for solving the odd-even classification problem. The number of hidden units needed is equal to the number of input units. Therefore, they simply count how many input number is activated.\n",
        "\n",
        "![Figure 2. Network structure for discriminating odd and even numbers](https://github.com/ouliang0128/Machine-Learning-Assignment1/blob/master/figure_2.png?raw=true)\n",
        "\n",
        "**Figure 2**. Network structure for discriminating odd and even numbers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fB1vt-mIjs1G",
        "colab_type": "text"
      },
      "source": [
        "**Problem 3: The Encoding Problem**\n",
        "\n",
        "Using intermediate values other than only 0 (fully turned off) and 1 (fully turned on) as output values increase the flexibility of the learning system.\n",
        "\n",
        "**Table 1** shows how inputs are transformed into values in the range of [0,1] for a single unit. The benefit of using continuous values is the system can reduce the number of hidden units employed.\n",
        "\n",
        "\n",
        "> Input Patterns | Signleton Hidden Unit | Remaining Hidden Units | Output Patterns\n",
        ">--- | --- | --- | ---\n",
        ">0        |     10           |         0        |        1/1/1/0       |   0010\n",
        ">1        |     11           |        .2        |        1/1/0/0       |   0001\n",
        ">2        |     00           |        .6        |      .5/0/0/.3       |   1000\n",
        ">3        |     01           |         1        |        0/0/0/1       |   0100\n",
        "\n",
        "**Table 1**. pattern transformation with only one unit in an intermediate layer.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-r0F_UmHjvhe",
        "colab_type": "text"
      },
      "source": [
        "**Problem 4: Symmetry**\n",
        "\n",
        "Only 2 hidden units are enough for classifying whether an input pattern is symmetric or not. The network does that by applying symmetry weights for all input neurons with opposite signs, such as 1, -2, 4, -4, 2, -1 for one neuron and -1, 2, -4, 4, -2, 1 for the other. The negative biases on hidden units and positive bias on the output units insure that the output only turns on for symmetric input values.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdvRcABsjy1l",
        "colab_type": "text"
      },
      "source": [
        "**Problem 5: Addition**\n",
        "\n",
        "For two “m” length of binary bits, a minimal network needs 2m inputs units, m carry (hidden) units and m+1 output units. Because the lower carry unit should be considered as one input units of a higher carry unit, an appropriate connection of hidden layer is necessary. This local minima problem can be solved by adding one more hidden units. \n",
        "\n",
        "This Addition problem demonstrates that if the number of hidden units is more than minimal requirement, it enhances the interpretability and avoids localist (stuck in local minima). However, hidden units become hard to be interpreted, and their importance is the same.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "noKi04b3j42r",
        "colab_type": "text"
      },
      "source": [
        "**Problem 6: The Negation Problem** \n",
        "\n",
        "This is the problem in which one input is considered as a \"sign\" to control whether the n outputs should be exactly the same as the rest of n inputs or the complement of those inputs. In this case, n hidden units are needed to detect the combination of the \"sign\" and every input unit."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnMIS_Xxj-KI",
        "colab_type": "text"
      },
      "source": [
        "**Problem 7: The T-C Problem** \n",
        "\n",
        "A system is designed to discriminate the shape of “T” and “C”, which consist of 5 squares. Each hidden units measures the inputs' shape by projecting the inputs into a square 3 x 3 region. Feature detector of all hidden units is the same, how due to the location and rotation of the inputs is uncertain. A two-dimensional grid of hidden units is required to scan the input space for pattern recognition. \n",
        "\n",
        "Features detected of the hidden units “includes on-center-off-surround”, “vertical bar”, “diagonal bar” and “compactness”.\n",
        "\n",
        "One conclusion from the solutions of this problem is that inhibit the hidden units at the beginning of the learning can avoid correct answer by random connections. That means without turning on by inputs, the hidden units should be on.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGGPcOUGkbwg",
        "colab_type": "text"
      },
      "source": [
        "**Generalization:**\n",
        "\n",
        "This book than generalize the generalized delta rule to sigma-pi units and recurrent networks. For sigma-pi units with conjunction less than two, the error signal is given by\n",
        "$$\n",
        "δ_j=f'_j ((net)_j )=∑_{j,k}δ_k w_{kij}o_j\n",
        "$$\n",
        "For recurrent networks, they can be transformed into multiple layered feedforward network with same weights for every iteration. The experiment for “shift register” shows that the system will set all weights to be 0, but the one connects to its left to be within 200 sweeps and with learning rate $\\eta=0.25$. Another experiment of “complete sequences” let errors are injected at each time-step by comparing the remembered actual states of the output units with their desired states.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpzlojByREIk",
        "colab_type": "text"
      },
      "source": [
        "## Technical quality"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UpalKaBREIl",
        "colab_type": "text"
      },
      "source": [
        "In the aspects of theory inference and formula derivation, this book has a high quality. This is because it derives its formulas step by step with an explicit explanation of all variables and notations. A total 17 equations, 12 tables and 17 figures are introduced for supporting its arguments.\n",
        "\n",
        "Moreover, limitation and issues of backpropagation are widely discussed, which facilities further relative research. For example, although this book identifies 2 local minima problems as they are discussed, they point out that more studies need to be conducted under different conditions. Another example is that they state the limitations when testing the generalized delta rule on Recurrent Nets and sigma-pi units. \n",
        "\n",
        "In the aspect of simulations, although it explores many problems and evaluates the learning procedure by the time complexity and accuracy, it lacks the explanation for how the backpropagation algorithm is applied to each problem. Therefore, although the results look pretty neat, it cannot be replicated by readers, or at least hard to be re-implemented.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EW7uZYRsREIm",
        "colab_type": "text"
      },
      "source": [
        "## Application and X-factor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAIYo6AlREIn",
        "colab_type": "text"
      },
      "source": [
        "Apart from backpropagation, there are numbers of optimization algorithms have developed for a neural network. One type of popular algorithms are Evolutionary Algorithms (EAs) which mimic natural evolutionary principles. EAs can be further divided into Evolutionary strategies (ES), Evolutionary Programming (EP), Genetic Algorithms (GAs), and Genetic Programming (GP). Take GAs as an example, it optimizes all weights in a network with the following process:\n",
        "\n",
        "\n",
        "1.   reproduction:\n",
        ">Different combinations of weights are evaluated and the best of them are selected\n",
        "\n",
        "\n",
        "\n",
        "2. recombination (crossover):\n",
        ">Interchange some weights in two sets of weights\n",
        "\t\n",
        "3. mutation:\n",
        ">Randomly change some weights\n",
        "\n",
        "The merit of GAs is that it can easily escape from local minima.\n",
        "Another type of optimization algorithm is Swarm Intelligence (SI), by which individual solution communicate with each other for finding the optima in the solution space.\n",
        "\n",
        "One example of SI is Particle Swarm Optimization (PSO), which is a population-based stochastic optimization technique developed by Dr. Eberhart and Dr. Kennedy in 1995. In PSO, every particle (solution) have its position $\\overrightarrow{x_i}$ and moving speed $\\overrightarrow{v_i}$. For each iteration, the moving speed is updated by the following formula (Kennedy 2010):\n",
        "$$\n",
        "\\overrightarrow{v_i}(t+1)=\\overrightarrow{v_i}(t)+c_1 φ_1 (\\overrightarrow{p_i}(t)-\\overrightarrow{x_i}(t))+c_2 φ_2 (\\overrightarrow{p_g}(t)-\\overrightarrow{x_i }(t))\n",
        "$$\n",
        "\n",
        "Where $c_1$ and $c_2$ are acceleration coefficients, often positive constants, $φ_1$ and $φ_2$ are random numbers in [0,1],  $\\overrightarrow{p_i}(t)$ is the best position of particle $\\overrightarrow{x_i}$ and $\\overrightarrow{p_g}(t)$ is the best position of all particles, t is the iteration. By updating the position through $\\overrightarrow{x_i}(t+1)=\\overrightarrow{x_i} (t)+\\overrightarrow{v_i}(t+1)$, all particles move toward the best one. **Figure 3** shows how a particle moving toward the best position in the solution space.\n",
        "\n",
        "![Figure 3. The updating strategy of a particle moving toward the best position in the solution space\n",
        "Although PSO is very efficient in converging to the best solution, it is likely to trap in certain local minima.\n",
        "](https://github.com/ouliang0128/Machine-Learning-Assignment1/blob/master/figure_3.png?raw=true)\n",
        "\n",
        "**Figure 3**. The updating strategy of a particle moving toward the best position in the solution space\n",
        "Although PSO is very efficient in converging to the best solution, it is likely to trap in certain local minima\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6ZU2OAtb5WA",
        "colab_type": "text"
      },
      "source": [
        "Another SI algorithm, called Firework Algorithm (FA) provides both efficiency and diversity. The framework of FA is generating new solutions (sparks) by old solutions (fireworks), the explosion (search) radius and density are defined by fireworks’ performances, as it shows in **Figure 4** (Tan & Zhu 2010). Selection strategy in FA is based on the distance (similarity) of particles so that the diversity of particles of the next generation is guaranteed. \n",
        "\n",
        "![Figure 4. The search strategy of FA. (a) is an explosion by a high fitness firework, whereas (b) is an explosion by a low fitness firework.\n",
        "](https://github.com/ouliang0128/Machine-Learning-Assignment1/blob/master/figure_4.png?raw=true)\n",
        "\n",
        "\n",
        "**Figure 4.** The search strategy of FA. (a) is an explosion by a high fitness firework, whereas (b) is an explosion by a low fitness firework."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PASXO0pHREIn",
        "colab_type": "text"
      },
      "source": [
        "## Presentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vOJJYqeREIo",
        "colab_type": "text"
      },
      "source": [
        "If the lowest rate the quality is 0 and the highest rate of quality is 5, I will rate this book with a rate of 4. Overall, the organization of this book well-aligned, terminologies in this book is well- explained. Therefore, one can easily grasp the main concept of \"backpropagation\" even as a beginner for machine learning. However, there are still some bad presentation approaches make me feel hard to follow the book. First, when it uses some definition discussed in other chapters, such as “semilinear”, “sigma-pi units”, there is no brief description at all. This explanation style makes those concepts impossible to understand due to other chapters are not available to readers. Second, it wastes length very much on calculating simple numerical additions for inputs and outputs rather than explaining why such additions should be happening. Third, many experiments on the research of this book are based on Minsky and Papert (1969)’s book. However, it assumes that readers should understand the research problems proposed by Minsky and Papert (1969), while in most cases they probably don't."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brm0FxAkREIo",
        "colab_type": "text"
      },
      "source": [
        "## References\n",
        "\n",
        "Kennedy, J. 2010, 'Particle swarm optimization', Encyclopedia of machine learning, pp. 760-6.\n",
        "\n",
        "Tan, Y. & Zhu, Y. 2010, 'Fireworks Algorithm for Optimization', eds Y. Tan, Y. Shi & K.C. Tan, Springer Berlin Heidelberg, pp. 355-64."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOkUi-1Tjmro",
        "colab_type": "text"
      },
      "source": [
        "# Appendices "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdWmh4cIjtU5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define a neuron\n",
        "import random\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "class neuron:\n",
        "# initiate the neuron\n",
        "  def __init__(self, layer='hidden',input_number=None):\n",
        "    self.__layer=layer\n",
        "    self.__bias = 0\n",
        "    self.net_input=0\n",
        "    self.output=0\n",
        "    self.error_signal=0\n",
        "    if self.__layer = 'hidden':      \n",
        "      self.weights=np.random.random(input_number)\n",
        "    if self.__layer = 'output':\n",
        "      self.weights=np.random.random(input_number)\n",
        "# calculate the net input\n",
        "  def cal_net_input(self,input_neurons):\n",
        "    self.net_input=0\n",
        "    for i in range (len(input_neurons)):\n",
        "      net_input+=self.weights[i]*input_neurons[i].output\n",
        "    return net_input\n",
        "  def cal_net_output(self):\n",
        "    if self.__layer!='input':\n",
        "# sigmoid function\n",
        "      self.output=1.0/(1+math.exp(-(self.net_input+self.__bias)))\n",
        "\n",
        "    \n",
        "    \n",
        "  \n",
        "      \n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DceRfLN34-ep",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# predict the output\n",
        "def predict_output(input):\n",
        "  \n",
        "# initiate all neurons\n",
        "  input1=neuron(layer='input')\n",
        "  input1.output=input[0]\n",
        "  input2=neuron(layer='input')\n",
        "  input2.output=input[1]\n",
        "  \n",
        "  hidden1=neuron(layer='hidden',input_number=2)\n",
        "  hidden2=neuron(layer='hidden',input_number=2)\n",
        "  \n",
        "  output_neuron=neuron(layer='output',input_number=2)\n",
        "  \n",
        "# calculate output for two hidden units\n",
        "  hidden1.cal_net_input([input1,input2])\n",
        "  hidden1.cal_net_output()\n",
        "  \n",
        "  hidden1.cal_net_input([input1,input2])\n",
        "  hidden1.cal_net_output()\n",
        "  \n",
        "# calculate output the output units\n",
        "  output_neuron.cal_net_input([hidden1,hidden2])\n",
        "  res=output_neuron.cal_net_output()\n",
        "  return res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QL4VeJd48U-m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# calculate error singal\n",
        "def update_error_signal(target):\n",
        "  output_neuron.error_signal = output_neuron.output*(1-output_neuron.output)*(target-output_neuron.output)\n",
        "  \n",
        "  hidden1.error_signal = hidden1.output*(1-hidden1.output)*output_neuron.weights[0]*output_neuron.error_signal\n",
        "  hidden2.error_signal = hidden1.output*(1-hidden1.output)*output_neuron.weights[1]*output_neuron.error_signal\n",
        "  \n",
        "  input1.error_signal = input1.output*(1-input1.output)*(hidden1.weights[0]*hidden1.error_signal+hidden2.weights[0]*hidden2.error_signal)\n",
        "  input2.error_signal = input2.output*(1-input2.output)*(hidden1.weights[1]*hidden1.error_signal+hidden2.weights[1]*hidden2.error_signal)\n",
        "  \n",
        "  \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZG9l7ySws6U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b18ef938-dda9-48fc-f43a-5b66538acf80"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "res = np.random.random(5)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.01875265 0.91995485 0.27937449 0.01615428 0.11876439]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}